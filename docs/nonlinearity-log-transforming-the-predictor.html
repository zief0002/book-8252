<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Unit 2: Nonlinearity: Log-Transforming the Predictor | EPsy 8252 Notes</title>
  <meta name="description" content="These are the notes for EPsy 8252.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Unit 2: Nonlinearity: Log-Transforming the Predictor | EPsy 8252 Notes" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="These are the notes for EPsy 8252." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Unit 2: Nonlinearity: Log-Transforming the Predictor | EPsy 8252 Notes" />
  
  <meta name="twitter:description" content="These are the notes for EPsy 8252." />
  

<meta name="author" content="Andrew Zieffler">


<meta name="date" content="2019-02-05">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="pretty-printing-tables-in-markdown.html">
<link rel="next" href="nonlinearity-log-transforming-the-outcome.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<link href="libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="libs/pagedtable-1.1/js/pagedtable.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="print.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">EPsy 8252 Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="1" data-path="rmarkdown.html"><a href="rmarkdown.html"><i class="fa fa-check"></i><b>1</b> R Markdown</a><ul>
<li class="chapter" data-level="" data-path="rmarkdown.html"><a href="rmarkdown.html#preparation"><i class="fa fa-check"></i>Preparation</a></li>
<li class="chapter" data-level="1.1" data-path="rmarkdown.html"><a href="rmarkdown.html#notes"><i class="fa fa-check"></i><b>1.1</b> Notes</a></li>
<li class="chapter" data-level="1.2" data-path="rmarkdown.html"><a href="rmarkdown.html#other-resources"><i class="fa fa-check"></i><b>1.2</b> Other Resources</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="pretty-printing-tables-in-markdown.html"><a href="pretty-printing-tables-in-markdown.html"><i class="fa fa-check"></i>Pretty-Printing Tables in Markdown</a><ul>
<li class="chapter" data-level="" data-path="pretty-printing-tables-in-markdown.html"><a href="pretty-printing-tables-in-markdown.html#summary-statistics-table"><i class="fa fa-check"></i>Summary Statistics Table</a></li>
<li class="chapter" data-level="" data-path="pretty-printing-tables-in-markdown.html"><a href="pretty-printing-tables-in-markdown.html#correlation-table"><i class="fa fa-check"></i>Correlation Table</a></li>
<li class="chapter" data-level="" data-path="pretty-printing-tables-in-markdown.html"><a href="pretty-printing-tables-in-markdown.html#regression-table-single-model"><i class="fa fa-check"></i>Regression Table: Single Model</a></li>
<li class="chapter" data-level="" data-path="pretty-printing-tables-in-markdown.html"><a href="pretty-printing-tables-in-markdown.html#regression-table-multiple-models"><i class="fa fa-check"></i>Regression Table: Multiple Models</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html"><i class="fa fa-check"></i><b>2</b> Nonlinearity: Log-Transforming the Predictor</a><ul>
<li class="chapter" data-level="" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#preparation-1"><i class="fa fa-check"></i>Preparation</a></li>
<li class="chapter" data-level="2.1" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#dataset-and-research-question"><i class="fa fa-check"></i><b>2.1</b> Dataset and Research Question</a></li>
<li class="chapter" data-level="2.2" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#log-transformation-of-a-variable"><i class="fa fa-check"></i><b>2.2</b> Log-Transformation of a Variable</a><ul>
<li class="chapter" data-level="2.2.1" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#quick-refresher-on-logarithms"><i class="fa fa-check"></i><b>2.2.1</b> Quick Refresher on Logarithms</a></li>
<li class="chapter" data-level="2.2.2" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#log-transforming-variables"><i class="fa fa-check"></i><b>2.2.2</b> Log-Transforming Variables</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#fitting-the-regression-model"><i class="fa fa-check"></i><b>2.3</b> Fitting the Regression Model</a><ul>
<li class="chapter" data-level="2.3.1" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#examine-the-assumption-of-linearity"><i class="fa fa-check"></i><b>2.3.1</b> Examine the Assumption of Linearity</a></li>
<li class="chapter" data-level="2.3.2" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#interpret-the-regression-results"><i class="fa fa-check"></i><b>2.3.2</b> Interpret the Regression Results</a></li>
<li class="chapter" data-level="2.3.3" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#better-interpretations-back-transforming"><i class="fa fa-check"></i><b>2.3.3</b> Better Interpretations: Back-transforming</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#alternative-method-of-fitting-the-model"><i class="fa fa-check"></i><b>2.4</b> Alternative Method of Fitting the Model</a></li>
<li class="chapter" data-level="2.5" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#plotting-the-fitted-model"><i class="fa fa-check"></i><b>2.5</b> Plotting the Fitted Model</a></li>
<li class="chapter" data-level="2.6" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#different-base-values-in-the-logarithm"><i class="fa fa-check"></i><b>2.6</b> Different Base Values in the Logarithm</a><ul>
<li class="chapter" data-level="2.6.1" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#comparing-the-output-from-the-two-bases"><i class="fa fa-check"></i><b>2.6.1</b> Comparing the Output from the Two Bases</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#base-e-logarithm-the-natural-logarithm"><i class="fa fa-check"></i><b>2.7</b> Base-<span class="math inline">\(e\)</span> Logarithm: The Natural Logarithm</a><ul>
<li class="chapter" data-level="2.7.1" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#using-the-natural-logarithm-in-a-regression-model"><i class="fa fa-check"></i><b>2.7.1</b> Using the Natural Logarithm in a Regression Model</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#including-covariates"><i class="fa fa-check"></i><b>2.8</b> Including Covariates</a><ul>
<li class="chapter" data-level="2.8.1" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#plot-of-the-model-results"><i class="fa fa-check"></i><b>2.8.1</b> Plot of the Model Results</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#polynomial-effects-vs.-log-transformations"><i class="fa fa-check"></i><b>2.9</b> Polynomial Effects vs. Log-Transformations</a></li>
<li class="chapter" data-level="" data-path="nonlinearity-log-transforming-the-predictor.html"><a href="nonlinearity-log-transforming-the-predictor.html#other-resources-1"><i class="fa fa-check"></i>Other Resources</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html"><i class="fa fa-check"></i><b>3</b> Nonlinearity: Log-Transforming the Outcome</a><ul>
<li class="chapter" data-level="" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#preparation-2"><i class="fa fa-check"></i>Preparation</a></li>
<li class="chapter" data-level="3.1" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#dataset-and-research-question-1"><i class="fa fa-check"></i><b>3.1</b> Dataset and Research Question</a></li>
<li class="chapter" data-level="3.2" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#examine-relationship-between-age-and-budget"><i class="fa fa-check"></i><b>3.2</b> Examine Relationship between Age and Budget</a></li>
<li class="chapter" data-level="3.3" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#transform-the-outcome-using-the-natural-logarithm-base-e"><i class="fa fa-check"></i><b>3.3</b> Transform the Outcome Using the Natural Logarithm (Base-e)</a></li>
<li class="chapter" data-level="3.4" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#re-analyze-using-the-log-transformed-budget"><i class="fa fa-check"></i><b>3.4</b> Re-analyze using the Log-Transformed Budget</a></li>
<li class="chapter" data-level="3.5" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#interpreting-the-regression-output"><i class="fa fa-check"></i><b>3.5</b> Interpreting the Regression Output</a><ul>
<li class="chapter" data-level="3.5.1" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#back-transforming-a-more-useful-interpretation"><i class="fa fa-check"></i><b>3.5.1</b> Back-Transforming: A More Useful Interpretation</a></li>
<li class="chapter" data-level="3.5.2" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#substituting-in-values-for-age-to-interpret-effects"><i class="fa fa-check"></i><b>3.5.2</b> Substituting in Values for Age to Interpret Effects</a></li>
<li class="chapter" data-level="3.5.3" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#approximate-interpretation-of-the-slope"><i class="fa fa-check"></i><b>3.5.3</b> Approximate Interpretation of the Slope</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#plotting-the-fitted-model-1"><i class="fa fa-check"></i><b>3.6</b> Plotting the Fitted Model</a></li>
<li class="chapter" data-level="3.7" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#relationship-between-mpaa-rating-and-budget"><i class="fa fa-check"></i><b>3.7</b> Relationship between MPAA Rating and Budget</a><ul>
<li class="chapter" data-level="3.7.1" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#regression-model"><i class="fa fa-check"></i><b>3.7.1</b> Regression Model</a></li>
<li class="chapter" data-level="3.7.2" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#mathematical-explanation-1"><i class="fa fa-check"></i><b>3.7.2</b> Mathematical Explanation</a></li>
<li class="chapter" data-level="3.7.3" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#approximate-interpretations"><i class="fa fa-check"></i><b>3.7.3</b> Approximate Interpretations</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#multiple-regression-main-effects-model"><i class="fa fa-check"></i><b>3.8</b> Multiple Regression: Main Effects Model</a><ul>
<li class="chapter" data-level="3.8.1" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#nested-f-test"><i class="fa fa-check"></i><b>3.8.1</b> Nested F-Test</a></li>
<li class="chapter" data-level="3.8.2" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#coefficient-level-interpretation"><i class="fa fa-check"></i><b>3.8.2</b> Coefficient-Level Interpretation</a></li>
<li class="chapter" data-level="3.8.3" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#plot-of-the-fitted-model"><i class="fa fa-check"></i><b>3.8.3</b> Plot of the Fitted Model</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="nonlinearity-log-transforming-the-outcome.html"><a href="nonlinearity-log-transforming-the-outcome.html#multiple-regression-interaction-model"><i class="fa fa-check"></i><b>3.9</b> Multiple Regression: Interaction Model</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="log-transformations-some-final-thoughts.html"><a href="log-transformations-some-final-thoughts.html"><i class="fa fa-check"></i>Log Transformations: Some Final Thoughts</a><ul>
<li class="chapter" data-level="" data-path="log-transformations-some-final-thoughts.html"><a href="log-transformations-some-final-thoughts.html#power-transformations"><i class="fa fa-check"></i>Power Transformations</a><ul>
<li class="chapter" data-level="" data-path="log-transformations-some-final-thoughts.html"><a href="log-transformations-some-final-thoughts.html#ladder-of-transformations"><i class="fa fa-check"></i>Ladder of Transformations</a></li>
<li class="chapter" data-level="" data-path="log-transformations-some-final-thoughts.html"><a href="log-transformations-some-final-thoughts.html#rule-of-the-bulge"><i class="fa fa-check"></i>Rule of the Bulge</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="probability-distributions.html"><a href="probability-distributions.html"><i class="fa fa-check"></i><b>4</b> Probability Distributions</a><ul>
<li class="chapter" data-level="" data-path="probability-distributions.html"><a href="probability-distributions.html#preparation-3"><i class="fa fa-check"></i>Preparation</a></li>
<li class="chapter" data-level="4.1" data-path="probability-distributions.html"><a href="probability-distributions.html#dataset-and-research-question-2"><i class="fa fa-check"></i><b>4.1</b> Dataset and Research Question</a></li>
<li class="chapter" data-level="4.2" data-path="probability-distributions.html"><a href="probability-distributions.html#normal-distribution"><i class="fa fa-check"></i><b>4.2</b> Normal Distribution</a><ul>
<li class="chapter" data-level="4.2.1" data-path="probability-distributions.html"><a href="probability-distributions.html#other-useful-r-functions-for-working-with-probability-distributions"><i class="fa fa-check"></i><b>4.2.1</b> Other Useful R Functions for Working with Probability Distributions</a></li>
<li class="chapter" data-level="4.2.2" data-path="probability-distributions.html"><a href="probability-distributions.html#finding-cumulative-probability"><i class="fa fa-check"></i><b>4.2.2</b> Finding Cumulative Probability</a></li>
<li class="chapter" data-level="4.2.3" data-path="probability-distributions.html"><a href="probability-distributions.html#cumulative-density-and-p-value"><i class="fa fa-check"></i><b>4.2.3</b> Cumulative Density and <span class="math inline">\(p\)</span>-Value</a></li>
<li class="chapter" data-level="4.2.4" data-path="probability-distributions.html"><a href="probability-distributions.html#finding-quantiles"><i class="fa fa-check"></i><b>4.2.4</b> Finding Quantiles</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="probability-distributions.html"><a href="probability-distributions.html#students-t-distribution"><i class="fa fa-check"></i><b>4.3</b> Student’s <span class="math inline">\(t\)</span>-Distribution</a><ul>
<li class="chapter" data-level="4.3.1" data-path="probability-distributions.html"><a href="probability-distributions.html#comparing-probability-densities"><i class="fa fa-check"></i><b>4.3.1</b> Comparing Probability Densities</a></li>
<li class="chapter" data-level="4.3.2" data-path="probability-distributions.html"><a href="probability-distributions.html#comparing-cumulative-densities"><i class="fa fa-check"></i><b>4.3.2</b> Comparing Cumulative Densities</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="probability-distributions.html"><a href="probability-distributions.html#using-the-t-distribution-in-regression"><i class="fa fa-check"></i><b>4.4</b> Using the <span class="math inline">\(t\)</span>-Distribution in Regression</a></li>
<li class="chapter" data-level="4.5" data-path="probability-distributions.html"><a href="probability-distributions.html#model-level-inference-the-f-distribution"><i class="fa fa-check"></i><b>4.5</b> Model-Level Inference: The <span class="math inline">\(F\)</span>-Distribution</a><ul>
<li class="chapter" data-level="4.5.1" data-path="probability-distributions.html"><a href="probability-distributions.html#testing-the-model-level-null-hypothesis"><i class="fa fa-check"></i><b>4.5.1</b> Testing the Model-Level Null Hypothesis</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="probability-distributions.html"><a href="probability-distributions.html#mean-squares-are-variance-estimates"><i class="fa fa-check"></i><b>4.6</b> Mean Squares are Variance Estimates</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html"><i class="fa fa-check"></i><b>5</b> Maximum Likelihood Estimation</a><ul>
<li class="chapter" data-level="" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#preparation-4"><i class="fa fa-check"></i>Preparation</a></li>
<li class="chapter" data-level="5.1" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#dataset-and-research-question-3"><i class="fa fa-check"></i><b>5.1</b> Dataset and Research Question</a></li>
<li class="chapter" data-level="5.2" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#joint-probability-density"><i class="fa fa-check"></i><b>5.2</b> Joint Probability Density</a></li>
<li class="chapter" data-level="5.3" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#likelihood"><i class="fa fa-check"></i><b>5.3</b> Likelihood</a></li>
<li class="chapter" data-level="5.4" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#maximum-likelihood"><i class="fa fa-check"></i><b>5.4</b> Maximum Likelihood</a><ul>
<li class="chapter" data-level="5.4.1" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#method-1-grid-search"><i class="fa fa-check"></i><b>5.4.1</b> Method 1: Grid Search</a></li>
<li class="chapter" data-level="5.4.2" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#log-likelihood"><i class="fa fa-check"></i><b>5.4.2</b> Log-Likelihood</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#maximum-likelihood-estimation-for-regression"><i class="fa fa-check"></i><b>5.5</b> Maximum Likelihood Estimation for Regression</a><ul>
<li class="chapter" data-level="5.5.1" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#large-search-spaces"><i class="fa fa-check"></i><b>5.5.1</b> Large Search Spaces</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#ml-estimation-in-regression-using-r"><i class="fa fa-check"></i><b>5.6</b> ML Estimation in Regression Using R</a><ul>
<li class="chapter" data-level="5.6.1" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#using-r-to-directly-compute-the-likelihood-and-log-likelihood"><i class="fa fa-check"></i><b>5.6.1</b> Using R to Directly Compute the Likelihood and Log-Likelihood</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="maximum-likelihood-estimation.html"><a href="maximum-likelihood-estimation.html#way-too-much-math"><i class="fa fa-check"></i><b>5.7</b> Way, Way, Way too Much Mathematics</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="information-criteria-for-model-selection.html"><a href="information-criteria-for-model-selection.html"><i class="fa fa-check"></i><b>6</b> Information Criteria for Model Selection</a><ul>
<li class="chapter" data-level="" data-path="information-criteria-for-model-selection.html"><a href="information-criteria-for-model-selection.html#preparation-5"><i class="fa fa-check"></i>Preparation</a></li>
<li class="chapter" data-level="6.1" data-path="information-criteria-for-model-selection.html"><a href="information-criteria-for-model-selection.html#dataset-and-research-question-4"><i class="fa fa-check"></i><b>6.1</b> Dataset and Research Question</a></li>
<li class="chapter" data-level="6.2" data-path="information-criteria-for-model-selection.html"><a href="information-criteria-for-model-selection.html#model-building"><i class="fa fa-check"></i><b>6.2</b> Model-Building</a><ul>
<li class="chapter" data-level="6.2.1" data-path="information-criteria-for-model-selection.html"><a href="information-criteria-for-model-selection.html#exploration-of-the-outcome"><i class="fa fa-check"></i><b>6.2.1</b> Exploration of the Outcome</a></li>
<li class="chapter" data-level="6.2.2" data-path="information-criteria-for-model-selection.html"><a href="information-criteria-for-model-selection.html#building-the-student-related-factors-model"><i class="fa fa-check"></i><b>6.2.2</b> Building the Student-Related Factors Model</a></li>
<li class="chapter" data-level="6.2.3" data-path="information-criteria-for-model-selection.html"><a href="information-criteria-for-model-selection.html#building-the-faculty-related-factors-model"><i class="fa fa-check"></i><b>6.2.3</b> Building the Faculty-Related Factors Model</a></li>
<li class="chapter" data-level="6.2.4" data-path="information-criteria-for-model-selection.html"><a href="information-criteria-for-model-selection.html#building-the-institution-related-factors-model"><i class="fa fa-check"></i><b>6.2.4</b> Building the Institution-Related Factors Model</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="information-criteria-for-model-selection.html"><a href="information-criteria-for-model-selection.html#candidate-statistical-models"><i class="fa fa-check"></i><b>6.3</b> Candidate Statistical Models</a></li>
<li class="chapter" data-level="6.4" data-path="information-criteria-for-model-selection.html"><a href="information-criteria-for-model-selection.html#log-likelihood-1"><i class="fa fa-check"></i><b>6.4</b> Log-Likelihood</a></li>
<li class="chapter" data-level="6.5" data-path="information-criteria-for-model-selection.html"><a href="information-criteria-for-model-selection.html#deviance-an-alternative-fit-value"><i class="fa fa-check"></i><b>6.5</b> Deviance: An Alternative Fit Value</a></li>
<li class="chapter" data-level="6.6" data-path="information-criteria-for-model-selection.html"><a href="information-criteria-for-model-selection.html#akiakes-information-criteria-aic"><i class="fa fa-check"></i><b>6.6</b> Akiake’s Information Criteria (AIC)</a></li>
<li class="chapter" data-level="6.7" data-path="information-criteria-for-model-selection.html"><a href="information-criteria-for-model-selection.html#empirical-support-for-hypotheses"><i class="fa fa-check"></i><b>6.7</b> Empirical Support for Hypotheses</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="moreinfocrit.html"><a href="moreinfocrit.html"><i class="fa fa-check"></i><b>7</b> Model Evidence</a><ul>
<li class="chapter" data-level="" data-path="moreinfocrit.html"><a href="moreinfocrit.html#preparation-6"><i class="fa fa-check"></i>Preparation</a></li>
<li class="chapter" data-level="7.1" data-path="moreinfocrit.html"><a href="moreinfocrit.html#dataset-and-research-question-5"><i class="fa fa-check"></i><b>7.1</b> Dataset and Research Question</a></li>
<li class="chapter" data-level="7.2" data-path="moreinfocrit.html"><a href="moreinfocrit.html#corrected-aic-aicc-adjusting-for-model-complexity-and-sample-size"><i class="fa fa-check"></i><b>7.2</b> Corrected AIC (AICc): Adjusting for Model Complexity and Sample Size</a></li>
<li class="chapter" data-level="7.3" data-path="moreinfocrit.html"><a href="moreinfocrit.html#model-selection-uncertainty"><i class="fa fa-check"></i><b>7.3</b> Model-Selection Uncertainty</a></li>
<li class="chapter" data-level="7.4" data-path="moreinfocrit.html"><a href="moreinfocrit.html#relative-likelihood-and-evidence-ratios"><i class="fa fa-check"></i><b>7.4</b> Relative Likelihood and Evidence Ratios</a></li>
<li class="chapter" data-level="7.5" data-path="moreinfocrit.html"><a href="moreinfocrit.html#model-probabilities"><i class="fa fa-check"></i><b>7.5</b> Model Probabilities</a></li>
<li class="chapter" data-level="7.6" data-path="moreinfocrit.html"><a href="moreinfocrit.html#tables-of-model-evidence"><i class="fa fa-check"></i><b>7.6</b> Tables of Model Evidence</a></li>
<li class="chapter" data-level="7.7" data-path="moreinfocrit.html"><a href="moreinfocrit.html#some-final-thoughts"><i class="fa fa-check"></i><b>7.7</b> Some Final Thoughts</a></li>
<li class="chapter" data-level="7.8" data-path="moreinfocrit.html"><a href="moreinfocrit.html#pretty-printing-tables-of-model-evidence"><i class="fa fa-check"></i><b>7.8</b> Pretty Printing Tables of Model Evidence</a></li>
<li class="chapter" data-level="" data-path="moreinfocrit.html"><a href="moreinfocrit.html#other-resources-2"><i class="fa fa-check"></i>Other Resources</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="intro-lmer.html"><a href="intro-lmer.html"><i class="fa fa-check"></i><b>8</b> Introduction to Mixed-Effects Models</a><ul>
<li class="chapter" data-level="" data-path="intro-lmer.html"><a href="intro-lmer.html#preparation-7"><i class="fa fa-check"></i>Preparation</a></li>
<li class="chapter" data-level="8.1" data-path="intro-lmer.html"><a href="intro-lmer.html#dataset-and-research-question-6"><i class="fa fa-check"></i><b>8.1</b> Dataset and Research Question</a></li>
<li class="chapter" data-level="8.2" data-path="intro-lmer.html"><a href="intro-lmer.html#join-the-student--and-classroom-level-data"><i class="fa fa-check"></i><b>8.2</b> Join the Student- and Classroom-Level Data</a></li>
<li class="chapter" data-level="8.3" data-path="intro-lmer.html"><a href="intro-lmer.html#fixed-effects-regression-model"><i class="fa fa-check"></i><b>8.3</b> Fixed-Effects Regression Model</a><ul>
<li class="chapter" data-level="8.3.1" data-path="intro-lmer.html"><a href="intro-lmer.html#residual-analysis"><i class="fa fa-check"></i><b>8.3.1</b> Residual Analysis</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="intro-lmer.html"><a href="intro-lmer.html#conceptual-idea-of-mixed-effects-models"><i class="fa fa-check"></i><b>8.4</b> Conceptual Idea of Mixed-Effects Models</a></li>
<li class="chapter" data-level="8.5" data-path="intro-lmer.html"><a href="intro-lmer.html#fitting-the-mixed-effects-regression-model-in-practice"><i class="fa fa-check"></i><b>8.5</b> Fitting the Mixed-Effects Regression Model in Practice</a></li>
<li class="chapter" data-level="8.6" data-path="intro-lmer.html"><a href="intro-lmer.html#example-2-life-satisfaction-of-nba-players"><i class="fa fa-check"></i><b>8.6</b> Example 2: Life Satisfaction of NBA Players</a><ul>
<li class="chapter" data-level="8.6.1" data-path="intro-lmer.html"><a href="intro-lmer.html#fit-the-mixed-effects-model"><i class="fa fa-check"></i><b>8.6.1</b> Fit the Mixed-Effects Model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="lmer-cross-sectional.html"><a href="lmer-cross-sectional.html"><i class="fa fa-check"></i><b>9</b> Linear Mixed-Effects Models: Cross-Sectional Analysis</a><ul>
<li class="chapter" data-level="" data-path="lmer-cross-sectional.html"><a href="lmer-cross-sectional.html#preparation-8"><i class="fa fa-check"></i>Preparation</a></li>
<li class="chapter" data-level="9.1" data-path="lmer-cross-sectional.html"><a href="lmer-cross-sectional.html#dataset-and-research-question-7"><i class="fa fa-check"></i><b>9.1</b> Dataset and Research Question</a></li>
<li class="chapter" data-level="9.2" data-path="lmer-cross-sectional.html"><a href="lmer-cross-sectional.html#unconditional-random-intercepts-model"><i class="fa fa-check"></i><b>9.2</b> Unconditional Random Intercepts Model</a><ul>
<li class="chapter" data-level="9.2.1" data-path="lmer-cross-sectional.html"><a href="lmer-cross-sectional.html#fitting-and-interpreting-the-model"><i class="fa fa-check"></i><b>9.2.1</b> Fitting and Interpreting the Model</a></li>
<li class="chapter" data-level="9.2.2" data-path="lmer-cross-sectional.html"><a href="lmer-cross-sectional.html#partitioning-unexplained-variation"><i class="fa fa-check"></i><b>9.2.2</b> Partitioning Unexplained Variation</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="lmer-cross-sectional.html"><a href="lmer-cross-sectional.html#including-student-level-predictors"><i class="fa fa-check"></i><b>9.3</b> Including Student-Level Predictors</a><ul>
<li class="chapter" data-level="9.3.1" data-path="lmer-cross-sectional.html"><a href="lmer-cross-sectional.html#evaluating-predictors"><i class="fa fa-check"></i><b>9.3.1</b> Evaluating Predictors</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="lmer-cross-sectional.html"><a href="lmer-cross-sectional.html#including-student-level-controls"><i class="fa fa-check"></i><b>9.4</b> Including Student-Level Controls</a></li>
<li class="chapter" data-level="9.5" data-path="lmer-cross-sectional.html"><a href="lmer-cross-sectional.html#including-school-level-controls"><i class="fa fa-check"></i><b>9.5</b> Including School-Level Controls</a></li>
<li class="chapter" data-level="9.6" data-path="lmer-cross-sectional.html"><a href="lmer-cross-sectional.html#displaying-the-results-of-the-fitted-models"><i class="fa fa-check"></i><b>9.6</b> Displaying the Results of the Fitted Models</a><ul>
<li class="chapter" data-level="9.6.1" data-path="lmer-cross-sectional.html"><a href="lmer-cross-sectional.html#table-of-fitted-models"><i class="fa fa-check"></i><b>9.6.1</b> Table of Fitted Models</a></li>
<li class="chapter" data-level="9.6.2" data-path="lmer-cross-sectional.html"><a href="lmer-cross-sectional.html#plot-of-final-models"><i class="fa fa-check"></i><b>9.6.2</b> Plot of “Final” Model(s)</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="lmer-cross-sectional.html"><a href="lmer-cross-sectional.html#other-resources-3"><i class="fa fa-check"></i>Other Resources</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="data-codebook.html"><a href="data-codebook.html"><i class="fa fa-check"></i>Data Codebooks</a><ul>
<li class="chapter" data-level="" data-path="data-codebook.html"><a href="data-codebook.html#ed-schools-2018"><i class="fa fa-check"></i>ed-schools-2018.csv</a></li>
<li class="chapter" data-level="" data-path="data-codebook.html"><a href="data-codebook.html#evaluations"><i class="fa fa-check"></i>evaluations.csv</a></li>
<li class="chapter" data-level="" data-path="data-codebook.html"><a href="data-codebook.html#fci-2015"><i class="fa fa-check"></i>fci-2015.csv</a></li>
<li class="chapter" data-level="" data-path="data-codebook.html"><a href="data-codebook.html#mn-schools"><i class="fa fa-check"></i>mn-schools.csv</a></li>
<li class="chapter" data-level="" data-path="data-codebook.html"><a href="data-codebook.html#movies"><i class="fa fa-check"></i>movies.csv</a></li>
<li class="chapter" data-level="" data-path="data-codebook.html"><a href="data-codebook.html#nba"><i class="fa fa-check"></i>nba-player-data.csv and nba-team-data.csv</a></li>
<li class="chapter" data-level="" data-path="data-codebook.html"><a href="data-codebook.html#netherlands"><i class="fa fa-check"></i>netherlands-students.csv and netherlands-schools.csv</a></li>
<li class="chapter" data-level="" data-path="data-codebook.html"><a href="data-codebook.html#popular"><i class="fa fa-check"></i>popular-classroom.csv and popular-student.csv</a></li>
<li class="chapter" data-level="" data-path="data-codebook.html"><a href="data-codebook.html#riverview"><i class="fa fa-check"></i>riverview.csv</a></li>
<li class="chapter" data-level="" data-path="data-codebook.html"><a href="data-codebook.html#wine"><i class="fa fa-check"></i>wine.csv</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">EPsy 8252 Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="nonlinearity-log-transforming-the-predictor" class="section level1">
<h1><span class="header-section-number">Unit 2:</span> Nonlinearity: Log-Transforming the Predictor</h1>
<p>In this set of notes, you will learn about log-transforming the predictor in a regression model to account for nonlinearity.</p>
<hr />
<div id="preparation-1" class="section level3 unnumbered">
<h3>Preparation</h3>
<p>Before class you will need to do the following:</p>
<ul>
<li>Refresh your knowledge about logarithms by going though the <a href="https://www.khanacademy.org/math/algebra2/exponential-and-logarithmic-functions/introduction-to-logarithms/v/logarithms">Khan Academy Intro to Logarithms</a> tutorial.</li>
</ul>
<p><br /></p>
<hr />
</div>
<div id="dataset-and-research-question" class="section level2">
<h2><span class="header-section-number">2.1</span> Dataset and Research Question</h2>
<p>The data we will use in this set of notes, <em>mn-schools.csv</em> (see the <a href="data-codebook.html#mn-schools">data codebook</a> here), contains 2011 institutional data for <span class="math inline">\(n=33\)</span> Minnesota colleges and universities.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Load libraries</span>
<span class="kw">library</span>(broom)
<span class="kw">library</span>(dplyr)
<span class="kw">library</span>(ggplot2)
<span class="kw">library</span>(readr)
<span class="kw">library</span>(sm)
<span class="kw">library</span>(tidyr)

<span class="co"># Import data</span>
mn =<span class="st"> </span><span class="kw">read_csv</span>(<span class="dt">file =</span> <span class="st">&quot;~/Documents/github/epsy-8252/data/mn-schools.csv&quot;</span>)
<span class="kw">head</span>(mn)</code></pre>
<pre><code># A tibble: 6 x 6
     id name                               grad public   sat tuition
  &lt;dbl&gt; &lt;chr&gt;                             &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;
1     1 Augsburg College                   65.2      0  10.3    39.3
2     3 Bethany Lutheran College           52.6      0  10.6    30.5
3     4 Bethel University, Saint Paul, MN  73.3      0  11.4    39.4
4     5 Carleton College                   92.6      0  14      54.3
5     6 College of Saint Benedict          81.1      0  11.8    43.2
6     7 Concordia College at Moorhead      69.4      0  11.4    36.6</code></pre>
<p>Using these data, we will examine if (and how) academic “quality” of the student-body (measured by median composite SAT score) is related to institutional graduation rates.</p>
</div>
<div id="log-transformation-of-a-variable" class="section level2">
<h2><span class="header-section-number">2.2</span> Log-Transformation of a Variable</h2>
<p>Recall that the scatterplot of SAT scores and graduation rates suggested that the relationship between these variables was curvilinear.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-28"></span>
<img src="epsy-8252-notes_files/figure-html/unnamed-chunk-28-1.png" alt="Scatterplot of the relationship between median SAT score and six-year graduation rate. The loess smoother is also displayed." width="50%" />
<p class="caption">
Figure 2.1: Scatterplot of the relationship between median SAT score and six-year graduation rate. The loess smoother is also displayed.
</p>
</div>
<p>One way to model this nonlinearity was to fit a model that included a polynomial effect (quadratic). Another method of modeling nonlinearity is to transform the predictor (or outcome) using a nonlinear transformation. One commonly used nonlinear transformation is the logarithm. Below is a comparison of the quadratic function to the logarithmic function.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-29"></span>
<img src="epsy-8252-notes_files/figure-html/unnamed-chunk-29-1.png" alt="Quadratic and logarithmic functions." width="80%" />
<p class="caption">
Figure 2.2: Quadratic and logarithmic functions.
</p>
</div>
<p>The quadratic function shows continuous and diminishing growth followed by continuous and increasing loss (parabola; the function changes direction), while the logarithmic function models continuous, albeit diminishing, growth (the function does not change direction).</p>
<div id="quick-refresher-on-logarithms" class="section level3">
<h3><span class="header-section-number">2.2.1</span> Quick Refresher on Logarithms</h3>
<p>The logarithm is an inverse function of an exponent. Consider this example,</p>
<p><span class="math display">\[
\log_2 (32)
\]</span></p>
<p>The logarithm of 32 is the exponent to which the base, 2 in our example, must be raised to produce that number. In other words,</p>
<p><span class="math display">\[
\log_2 (32) \longrightarrow 2^{x} = 32 \longrightarrow x=5
\]</span></p>
<p>Thus,</p>
<p><span class="math display">\[
\log_2 (32) = 5
\]</span></p>
<p>To compute a logarithm using R, we use the <code>log()</code> function. We also specify the argument <code>base=</code>, since logarithms are unique to a particular base. For example, to compute the mathematical expression <span class="math inline">\(\log_2 (32)\)</span>, we use</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">log</span>(<span class="dv">32</span>, <span class="dt">base =</span> <span class="dv">2</span>)</code></pre>
<pre><code>[1] 5</code></pre>
<p>There is also a shortcut function to use base-2.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">log2</span>(<span class="dv">32</span>)</code></pre>
<pre><code>[1] 5</code></pre>
</div>
<div id="log-transforming-variables" class="section level3">
<h3><span class="header-section-number">2.2.2</span> Log-Transforming Variables</h3>
<p>For our purposes, we need to log-transform each value in a particular variable. Here, we will log-transform the SAT variable (using base-2).</p>
<pre class="sourceCode r"><code class="sourceCode r">mn =<span class="st"> </span>mn <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">L2sat =</span> <span class="kw">log</span>(sat, <span class="dt">base =</span> <span class="dv">2</span>)
    )

<span class="kw">head</span>(mn)</code></pre>
<pre><code># A tibble: 6 x 7
     id name                               grad public   sat tuition L2sat
  &lt;dbl&gt; &lt;chr&gt;                             &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;
1     1 Augsburg College                   65.2      0  10.3    39.3  3.36
2     3 Bethany Lutheran College           52.6      0  10.6    30.5  3.41
3     4 Bethel University, Saint Paul, MN  73.3      0  11.4    39.4  3.52
4     5 Carleton College                   92.6      0  14      54.3  3.81
5     6 College of Saint Benedict          81.1      0  11.8    43.2  3.57
6     7 Concordia College at Moorhead      69.4      0  11.4    36.6  3.52</code></pre>
<p>How does this log-transformed variable compare to the original SAT predictor. We can examine the density plot of both the original and log-transformed variables to answer this.</p>
<p><img src="epsy-8252-notes_files/figure-html/unnamed-chunk-33-1.png" width="6in" style="display: block; margin: auto;" /></p>
<ul>
<li>Comparing the shapes of the two variables, we see that the original variable was right-skewed. The log-transformed variable is also right-skewed, although it is LESS right-skewed than the original.</li>
<li>The scale is quite different between the two variables (one is, after all, log-transformed). This has greatly affected the variation. After log-transforming, the variation is much smaller.</li>
</ul>
<p>What happens when we use the log-transformed variable in a scatterplot with graduation rates?</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(<span class="dt">data =</span> mn, <span class="kw">aes</span>(<span class="dt">x =</span> L2sat, <span class="dt">y =</span> grad)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">se =</span> <span class="ot">FALSE</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Log-transformed SAT score&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Six-year graduation rate&quot;</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-34"></span>
<img src="epsy-8252-notes_files/figure-html/unnamed-chunk-34-1.png" alt="Scatterplot of the relationship between log-transformed median SAT score (base-2) and six-year graduation rate. The loess smoother is also displayed." width="50%" />
<p class="caption">
Figure 2.3: Scatterplot of the relationship between log-transformed median SAT score (base-2) and six-year graduation rate. The loess smoother is also displayed.
</p>
</div>
<p>The relationship between graduation rate and the log-transformed SAT scores is MORE linear than the relationship between graduation rates and the untransformed SAT scores. By transforming the variable using a nonlinear transformation (log) we have “linearized” the relationship with graduation rates. As such, we can fit a linear model to predict graduation rates using the Log-transformed SAT scores as a predictor.</p>
</div>
</div>
<div id="fitting-the-regression-model" class="section level2">
<h2><span class="header-section-number">2.3</span> Fitting the Regression Model</h2>
<p>To fit the model, we use the <code>lm()</code> function and input the log-transformed SAT scores as the predictor.</p>
<pre class="sourceCode r"><code class="sourceCode r">lm<span class="fl">.1</span> =<span class="st"> </span><span class="kw">lm</span>(grad <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>L2sat, <span class="dt">data =</span> mn)</code></pre>
<div id="examine-the-assumption-of-linearity" class="section level3">
<h3><span class="header-section-number">2.3.1</span> Examine the Assumption of Linearity</h3>
<p>Before examining the coefficients, we can scrutinize the residuals to see whether the log-transformation helped us meet the assumption of linearity.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Obtain residuals</span>
out =<span class="st"> </span><span class="kw">augment</span>(lm<span class="fl">.1</span>)

<span class="co"># Check linearity assumptions</span>
<span class="kw">ggplot</span>(<span class="dt">data =</span> out, <span class="kw">aes</span>(<span class="dt">x =</span> .fitted, <span class="dt">y =</span> .std.resid)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">0</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_smooth</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre>
<p><img src="epsy-8252-notes_files/figure-html/unnamed-chunk-36-1.png" width="3.5in" style="display: block; margin: auto;" /></p>
<p>The assumption looks reasonably met as the horizontal line of <span class="math inline">\(y=0\)</span> is encompassed in the confidence envelope of the loess smoother.</p>
</div>
<div id="interpret-the-regression-results" class="section level3">
<h3><span class="header-section-number">2.3.2</span> Interpret the Regression Results</h3>
<p>We can now look at the regression output and interpret the results.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Model-level output</span>
<span class="kw">glance</span>(lm<span class="fl">.1</span>)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["r.squared"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["adj.r.squared"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["sigma"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["statistic"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["p.value"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["df"],"name":[6],"type":["int"],"align":["right"]},{"label":["logLik"],"name":[7],"type":["dbl"],"align":["right"]},{"label":["AIC"],"name":[8],"type":["dbl"],"align":["right"]},{"label":["BIC"],"name":[9],"type":["dbl"],"align":["right"]},{"label":["deviance"],"name":[10],"type":["dbl"],"align":["right"]},{"label":["df.residual"],"name":[11],"type":["int"],"align":["right"]}],"data":[{"1":"0.8113","2":"0.8053","3":"7.386","4":"133.3","5":"9.296e-13","6":"2","7":"-111.8","8":"229.6","9":"234.1","10":"1691","11":"31"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>Examining the model-level output, we see that differences in <span class="math inline">\(\log_2(\mathrm{SAT})\)</span> explain 81.13% of the variation in graduation rates. This is statistically significant, <span class="math inline">\(F(1,~31)=133.3\)</span>, <span class="math inline">\(p&lt;.001\)</span>. Since differences in <span class="math inline">\(\log_2(\mathrm{SAT})\)</span> imply that there are differences in the raw SAT scores, we would typically just say that “differences in SAT scores explain 81.13% of the variation in graduation rates.”</p>
<p>Moving to the coefficient-level output,</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Coefficient-level output</span>
<span class="kw">tidy</span>(lm<span class="fl">.1</span>)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["term"],"name":[1],"type":["chr"],"align":["left"]},{"label":["estimate"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["std.error"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["statistic"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["p.value"],"name":[5],"type":["dbl"],"align":["right"]}],"data":[{"1":"(Intercept)","2":"-306.7","3":"31.868","4":"-9.624","5":"7.937e-11"},{"1":"L2sat","2":"106.4","3":"9.219","4":"11.546","5":"9.296e-13"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>We can write the fitted equation as,</p>
<p><span class="math display">\[
\hat{\mathrm{Graduation~Rate}} = -306.7 + 106.4\bigg[\log_2(\mathrm{SAT})\bigg]
\]</span></p>
<p>We can interpret the coefficients as we always do, recognizing that these interpretation are based on the log-transformed predictor.</p>
<ul>
<li>The intercept value of <span class="math inline">\(-306.7\)</span> is the predicted average graduation rate for all colleges/universities with a <span class="math inline">\(\log_2(\mathrm{SAT})\)</span> value of 0.</li>
<li>The slope value of 106.4 indicates that each one-unit difference in <span class="math inline">\(\log_2(\mathrm{SAT})\)</span> is associated with a 106.4-unit difference in graduation rate, on average.</li>
</ul>
</div>
<div id="better-interpretations-back-transforming" class="section level3">
<h3><span class="header-section-number">2.3.3</span> Better Interpretations: Back-transforming</h3>
<p>While these interpretations are technically correct, it is more helpful to your readers (and more conventional) to interpret any regression results in the metric of SAT scores rather than log-transformed SAT scores. This means we have to <em>back-transform the interpretations</em>. To back-transform a logarithm, we use its inverse function; exponentiation.</p>
<p>We interpreted the intercept as, “the predicted average graduation rate for all colleges/universities with a <span class="math inline">\(\log_2(\mathrm{SAT})\)</span> value of 0”. To interpret this using the metric of our SAT attribute, we have to understand what <span class="math inline">\(\log_2(\mathrm{SAT}) = 0\)</span> is.</p>
<p><span class="math display">\[
\log_2 (\mathrm{SAT}) = 0 \longrightarrow 2^{0} = \mathrm{SAT}
\]</span></p>
<p>In this computation, <span class="math inline">\(\mathrm{SAT}=1\)</span>. Thus, rather than using the log-transformed interpretation, we can, instead, interpret the intercept as,</p>
<blockquote>
<p>The predicted average graduation rate for all colleges/universities with a SAT measurement of 1 (median SAT = 100) is <span class="math inline">\(-306.7\)</span>. Since there are no colleges/universities in our data that have a SAT value of 1, this is extrapolation.</p>
</blockquote>
<p>What about the slope? Our interpretation was that “each one-unit difference in <span class="math inline">\(\log_2(\mathrm{SAT})\)</span> is associated with a 106.4-unit difference in graduation rate, on average.” Working with the same ideas of back-transformation, we need to understand what a one-unit difference in <span class="math inline">\(\log_2(\mathrm{SAT})\)</span> means. Consider four values of <span class="math inline">\(\log_2(\mathrm{SAT})\)</span> that are each one-unit apart:</p>
<p><span class="math display">\[
\log_2(\mathrm{SAT}) = 1\\
\log_2(\mathrm{SAT}) = 2\\
\log_2(\mathrm{SAT}) = 3\\
\log_2(\mathrm{SAT}) = 4
\]</span></p>
<p>If we back-transform each of these, then we can see how the four values of the raw SAT variable would differ.</p>
<p><span class="math display">\[
\begin{split}
\mathrm{SAT} &amp;= 2^1 = 2\\
\mathrm{SAT} &amp;= 2^2 = 4\\
\mathrm{SAT} &amp;= 2^3 = 8\\
\mathrm{SAT} &amp;= 2^4 = 16
\end{split}
\]</span></p>
<p>When <span class="math inline">\(\log_2(\mathrm{SAT})\)</span> is increased by one-unit, the raw SAT value is doubled. We can use this in our interpretation of slope:</p>
<blockquote>
<p>A doubling of the SAT value is associated with a 106.4-unit difference in graduation rate, on average.</p>
</blockquote>
<p>The technical language for doubling is a “two-fold difference”. So we would conventionally interpret this as:</p>
<blockquote>
<p>Each two-fold difference in SAT value is associated with a 106.4-unit difference in graduation rate, on average.</p>
</blockquote>
<p>To understand this further, consider a specific school, say Augsburg. Their measurement on the SAT variable is 10.3, and their log-transformed SAT score is 3.36. Using the fitted regression equation (which employs the log-transformed SAT),</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="fl">-306.7</span> <span class="op">+</span><span class="st"> </span><span class="fl">106.4</span> <span class="op">*</span><span class="st"> </span><span class="fl">3.36</span></code></pre>
<pre><code>[1] 50.8</code></pre>
<p>Augsburg’s predicted graduation rate would be 50.8. If we increase the <code>L2sat</code> score by 1 to 4.36 (which is equivalent to a raw SAT measurement of 20.6; double 10.3), their predicted graduation rate is,</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="fl">-306.7</span> <span class="op">+</span><span class="st"> </span><span class="fl">106.4</span> <span class="op">*</span><span class="st"> </span><span class="fl">4.36</span></code></pre>
<pre><code>[1] 157.2</code></pre>
<p>This is an increase of 106.4.</p>
</div>
</div>
<div id="alternative-method-of-fitting-the-model" class="section level2">
<h2><span class="header-section-number">2.4</span> Alternative Method of Fitting the Model</h2>
<p>Rather that create the log-transformed SAT score in the data, we can use the <code>log()</code> function on SAT directly in the <code>lm()</code> computation.</p>
<pre class="sourceCode r"><code class="sourceCode r">lm<span class="fl">.1</span> =<span class="st"> </span><span class="kw">lm</span>(grad <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">log</span>(sat, <span class="dt">base =</span> <span class="dv">2</span>), <span class="dt">data =</span> mn)

<span class="co"># Model-level output</span>
<span class="kw">glance</span>(lm<span class="fl">.1</span>)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["r.squared"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["adj.r.squared"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["sigma"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["statistic"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["p.value"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["df"],"name":[6],"type":["int"],"align":["right"]},{"label":["logLik"],"name":[7],"type":["dbl"],"align":["right"]},{"label":["AIC"],"name":[8],"type":["dbl"],"align":["right"]},{"label":["BIC"],"name":[9],"type":["dbl"],"align":["right"]},{"label":["deviance"],"name":[10],"type":["dbl"],"align":["right"]},{"label":["df.residual"],"name":[11],"type":["int"],"align":["right"]}],"data":[{"1":"0.8113","2":"0.8053","3":"7.386","4":"133.3","5":"9.296e-13","6":"2","7":"-111.8","8":"229.6","9":"234.1","10":"1691","11":"31"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Coefficient-level output</span>
<span class="kw">tidy</span>(lm<span class="fl">.1</span>)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["term"],"name":[1],"type":["chr"],"align":["left"]},{"label":["estimate"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["std.error"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["statistic"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["p.value"],"name":[5],"type":["dbl"],"align":["right"]}],"data":[{"1":"(Intercept)","2":"-306.7","3":"31.868","4":"-9.624","5":"7.937e-11"},{"1":"log(sat, base = 2)","2":"106.4","3":"9.219","4":"11.546","5":"9.296e-13"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>Using this method of fitting the model will be useful as we plot the fitted model.</p>
</div>
<div id="plotting-the-fitted-model" class="section level2">
<h2><span class="header-section-number">2.5</span> Plotting the Fitted Model</h2>
<p>To aid interpretation of the effect of SAT on graduation rate, we can plot the fitted model. If we used the method of fitting in which we used <code>log()</code> directly in the <code>lm()</code> function, we only need to set up a sequence of SAT values, predict graduation rates using the fitted model, and finally connect these values using a line.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Set up data</span>
plot_data =<span class="st"> </span><span class="kw">crossing</span>(
    <span class="dt">sat =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="fl">8.9</span>, <span class="dt">to =</span> <span class="fl">14.0</span>, <span class="dt">by =</span> <span class="fl">0.1</span>)
    ) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="co"># Predict</span>
    <span class="dt">yhat =</span> <span class="kw">predict</span>(lm<span class="fl">.1</span>, <span class="dt">newdata =</span> .)
  )

<span class="co"># Examine data</span>
<span class="kw">head</span>(plot_data)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["sat"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["yhat"],"name":[2],"type":["dbl"],"align":["right"]}],"data":[{"1":"8.9","2":"28.98"},{"1":"9.0","2":"30.70"},{"1":"9.1","2":"32.40"},{"1":"9.2","2":"34.07"},{"1":"9.3","2":"35.73"},{"1":"9.4","2":"37.38"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Plot</span>
<span class="kw">ggplot</span>(<span class="dt">data =</span> plot_data, <span class="kw">aes</span>(<span class="dt">x =</span> sat, <span class="dt">y =</span> yhat)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_line</span>() <span class="op">+</span>
<span class="st">    </span><span class="kw">theme_bw</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Median SAT score (in hundreds)&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Predicted graduation rate&quot;</span>)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-42"></span>
<img src="epsy-8252-notes_files/figure-html/unnamed-chunk-42-1.png" alt="Plot of the predicted graduation rates as a function of median SAT score (in hundreds). The non-linearity in the plot indicates that there is a diminishing positive effect of SAT on graduation rates." width="50%" />
<p class="caption">
Figure 2.4: Plot of the predicted graduation rates as a function of median SAT score (in hundreds). The non-linearity in the plot indicates that there is a diminishing positive effect of SAT on graduation rates.
</p>
</div>
</div>
<div id="different-base-values-in-the-logarithm" class="section level2">
<h2><span class="header-section-number">2.6</span> Different Base Values in the Logarithm</h2>
<p>The base value we used in the <code>log()</code> function in the previous example was base-2. Using a base value of 2 was an arbitrary choice. We can use any base value we want. For example, what happens if we use base-10.</p>
<pre class="sourceCode r"><code class="sourceCode r">mn =<span class="st"> </span>mn <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">L10sat =</span> <span class="kw">log</span>(mn<span class="op">$</span>sat, <span class="dt">base =</span> <span class="dv">10</span>)
  )

<span class="co"># Examine data</span>
<span class="kw">head</span>(mn)</code></pre>
<pre><code># A tibble: 6 x 8
     id name                         grad public   sat tuition L2sat L10sat
  &lt;dbl&gt; &lt;chr&gt;                       &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;
1     1 Augsburg College             65.2      0  10.3    39.3  3.36   1.01
2     3 Bethany Lutheran College     52.6      0  10.6    30.5  3.41   1.03
3     4 Bethel University, Saint P…  73.3      0  11.4    39.4  3.52   1.06
4     5 Carleton College             92.6      0  14      54.3  3.81   1.15
5     6 College of Saint Benedict    81.1      0  11.8    43.2  3.57   1.07
6     7 Concordia College at Moorh…  69.4      0  11.4    36.6  3.52   1.06</code></pre>
<p>Comparing the logarithms of the SAT attribute using base-10 to those using base-2 we see that the base-10 logarithms are smaller. This is because now we are using the base of 10 in our exponent (rather than 2). For example, for Augsburg,</p>
<p><span class="math display">\[
10^{1.013} = 10.3
\]</span></p>
<p>If we fit a model using the base-10 logarithm,</p>
<pre class="sourceCode r"><code class="sourceCode r">lm<span class="fl">.2</span> =<span class="st"> </span><span class="kw">lm</span>(grad <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">log</span>(sat, <span class="dt">base =</span> <span class="dv">10</span>), <span class="dt">data =</span> mn)

<span class="co"># Model-level output</span>
<span class="kw">glance</span>(lm<span class="fl">.2</span>)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["r.squared"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["adj.r.squared"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["sigma"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["statistic"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["p.value"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["df"],"name":[6],"type":["int"],"align":["right"]},{"label":["logLik"],"name":[7],"type":["dbl"],"align":["right"]},{"label":["AIC"],"name":[8],"type":["dbl"],"align":["right"]},{"label":["BIC"],"name":[9],"type":["dbl"],"align":["right"]},{"label":["deviance"],"name":[10],"type":["dbl"],"align":["right"]},{"label":["df.residual"],"name":[11],"type":["int"],"align":["right"]}],"data":[{"1":"0.8113","2":"0.8053","3":"7.386","4":"133.3","5":"9.296e-13","6":"2","7":"-111.8","8":"229.6","9":"234.1","10":"1691","11":"31"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>Examining the model-level output, we see that differences in <span class="math inline">\(\log_{10}(\mathrm{SAT})\)</span> explain 81.13% of the variation in graduation rates. Or simply, that differences in SAT scores explain 81.13% of the variation in graduation rates. This is statistically significant, <span class="math inline">\(F(1,~31)=133.3\)</span>, <span class="math inline">\(p&lt;.001\)</span>. These model-level results are the same as when we used the base-2 logarithm.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Coefficient-level output</span>
<span class="kw">tidy</span>(lm<span class="fl">.2</span>)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["term"],"name":[1],"type":["chr"],"align":["left"]},{"label":["estimate"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["std.error"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["statistic"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["p.value"],"name":[5],"type":["dbl"],"align":["right"]}],"data":[{"1":"(Intercept)","2":"-306.7","3":"31.87","4":"-9.624","5":"7.937e-11"},{"1":"log(sat, base = 10)","2":"353.6","3":"30.62","4":"11.546","5":"9.296e-13"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>The fitted equation is,</p>
<p><span class="math display">\[
\hat{\mathrm{Graduation~Rate}} = -306.7 + 353.6\bigg[\log_{10}(\mathrm{SAT})\bigg]
\]</span></p>
<p>We can interpret the coefficients using the base-10 logarithm of SAT scores as:</p>
<ul>
<li>The intercept value of <span class="math inline">\(-306.7\)</span> is the predicted average graduation rate for all colleges/universities with a <span class="math inline">\(\log_{10}(\mathrm{SAT})\)</span> value of 0.</li>
<li>The slope value of 353.6 indicates that each one-unit difference in <span class="math inline">\(\log_{10}(\mathrm{SAT})\)</span> is associated with a 353.6-unit difference in graduation rate, on average.</li>
</ul>
<p>Better yet, we can <em>back-transform the interpretations</em> so that we are using SAT scores rather than <span class="math inline">\(\log_{10}(\mathrm{SAT})\)</span> scores.</p>
<ul>
<li>The predicted average graduation rate for all colleges/universities with a SAT value of 1 (median SAT score = 100) is <span class="math inline">\(-306.7\)</span>.</li>
<li>Each <em>ten-fold</em> difference in SAT is associated with a 353.6-unit difference in graduation rate, on average.</li>
</ul>
<p>To further think about the effect of SAT, if Augsburg improved its median SAT score ten-fold (i.e., going from a SAT value of 10.3 to a value of 103) we would predict its graduation rate to go up by 353.6.</p>
<div id="comparing-the-output-from-the-two-bases" class="section level3">
<h3><span class="header-section-number">2.6.1</span> Comparing the Output from the Two Bases</h3>
<p>The model-level information is all the same. Furthermore, the intercepts (and SE and <span class="math inline">\(p\)</span>-value) was the same across both models. The slope coefficients and SEs were different in the two models, but the <span class="math inline">\(t\)</span>-value and <span class="math inline">\(p\)</span>-value for the effect of SAT was identical for both base-2 and base-10. The only real difference in using base-10 vs. base-2 in the logarithm is in the interpretation of the SAT effect.</p>
<p>What if we look at the residual fit?</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-46"></span>
<img src="epsy-8252-notes_files/figure-html/unnamed-chunk-46-1.png" alt="Standardized residuals versus the fitted values for the models fitted with the log-2 predictor (left) and the log-10 predictor (right)." width="80%" />
<p class="caption">
Figure 2.5: Standardized residuals versus the fitted values for the models fitted with the log-2 predictor (left) and the log-10 predictor (right).
</p>
</div>

<p>The residuals fit EXACTLY the same. Why is this? Let’s again use Augsburg as an example. Using the fitted model that employed the base-2 logarithm, we found that Augsburg’s predicted graduation rate was,</p>
<p><span class="math display">\[
\begin{split}
\hat{\mathrm{Graduation~Rate}} &amp;= -306.7 + 106.4\bigg[\log_2(10.3)\bigg] \\
&amp;= -306.7 + 106.4\bigg[3.36\bigg] \\
&amp;= 50.8
\end{split}
\]</span></p>
<p>Using the model that employed the base-10 logarithm, Augsburg’s predicted graduation rate would be</p>
<p><span class="math display">\[
\begin{split}
\hat{\mathrm{Graduation~Rate}} &amp;= -306.7 + 353.6\bigg[\log_{10}(10.3)\bigg] \\
&amp;= -306.7 + 353.6\bigg[1.01\bigg] \\
&amp;= 50.8
\end{split}
\]</span></p>
<p>Augsburg’s predicted graduation rate is <em>exactly the same</em> in the two models. This implies that Augsburg’s residual would also be the same in the two models. This is true for every college. Because of this, increasing (or decreasing) the base used in the logarithm does not help improve the fit of the model. The fit is exactly the same no matter which base you choose.</p>
<p>The only thing that changes when you choose a different base is the interpretation of the slope. You should choose the base to facilitate interpretation. For example, does it make more sense to talk about a <em>two-fold</em> difference in the predictor? A <em>five-fold</em> difference in the predictor? A <em>ten-fold</em> difference in the predictor?</p>
</div>
</div>
<div id="base-e-logarithm-the-natural-logarithm" class="section level2">
<h2><span class="header-section-number">2.7</span> Base-<span class="math inline">\(e\)</span> Logarithm: The Natural Logarithm</h2>
<p>In our example, neither of the bases we examined is satisfactory in terms of talking about the effect of SAT. Two-fold differences in SAT are very unlikely, to say anything of ten-fold differences. One base that is commonly used for log-transformations is base-<span class="math inline">\(e\)</span>. <span class="math inline">\(e\)</span> is a mathematical constant (Euler’s number) that is approximately equal to 2.71828. We can obtain this by using the <code>exp()</code> function in R. This function takes <span class="math inline">\(e\)</span> to some exponent that is given as the argument. So to obtain the approximation of <span class="math inline">\(e\)</span> we use</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">exp</span>(<span class="dv">1</span>)</code></pre>
<pre><code>[1] 2.718</code></pre>
<p>The logarithm (base-<span class="math inline">\(e\)</span>) for a number, referred to as the <em>natural logarithm</em>, can be obtained using the <code>log()</code> function with the argument <code>base=exp(1)</code>. However, this base is so commonly used that it is the default value for the <code>base=</code> argument. So, if we use the <code>log()</code> function without defining the <code>base=</code> argument, it will automatically use base-<span class="math inline">\(e\)</span>. For example, the natural logarithm of Augsburg’s SAT score of 1030 can be computed as</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">log</span>(<span class="fl">10.3</span>)</code></pre>
<pre><code>[1] 2.332</code></pre>
<p>If we took <span class="math inline">\(e^{2.332}\)</span> we would obtain 10.3. The natural logarithm even has its own mathematical notation; <span class="math inline">\(\ln\)</span>. For example, we would mathematically express the natural logarithm of 10.3 as</p>
<p><span class="math display">\[
\ln (10.3) = 2.332.
\]</span></p>
<div id="using-the-natural-logarithm-in-a-regression-model" class="section level3">
<h3><span class="header-section-number">2.7.1</span> Using the Natural Logarithm in a Regression Model</h3>
<p>Below we regress graduation rates on the log-transformed SAT scores, using the natural logarithm.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Fit model</span>
lm<span class="fl">.3</span> =<span class="st"> </span><span class="kw">lm</span>(grad <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span><span class="kw">log</span>(sat), <span class="dt">data =</span> mn)

<span class="co"># Model-level output</span>
<span class="kw">glance</span>(lm<span class="fl">.3</span>)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["r.squared"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["adj.r.squared"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["sigma"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["statistic"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["p.value"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["df"],"name":[6],"type":["int"],"align":["right"]},{"label":["logLik"],"name":[7],"type":["dbl"],"align":["right"]},{"label":["AIC"],"name":[8],"type":["dbl"],"align":["right"]},{"label":["BIC"],"name":[9],"type":["dbl"],"align":["right"]},{"label":["deviance"],"name":[10],"type":["dbl"],"align":["right"]},{"label":["df.residual"],"name":[11],"type":["int"],"align":["right"]}],"data":[{"1":"0.8113","2":"0.8053","3":"7.386","4":"133.3","5":"9.296e-13","6":"2","7":"-111.8","8":"229.6","9":"234.1","10":"1691","11":"31"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>As with any base, using base-<span class="math inline">\(e\)</span> results in the same model-level information (<span class="math inline">\(R^2=.811\)</span>, <span class="math inline">\(F(1,~31)=133.3\)</span>, <span class="math inline">\(p&lt;.001\)</span>).</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Coefficient-level output</span>
<span class="kw">tidy</span>(lm<span class="fl">.3</span>)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["term"],"name":[1],"type":["chr"],"align":["left"]},{"label":["estimate"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["std.error"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["statistic"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["p.value"],"name":[5],"type":["dbl"],"align":["right"]}],"data":[{"1":"(Intercept)","2":"-306.7","3":"31.87","4":"-9.624","5":"7.937e-11"},{"1":"log(sat)","2":"153.6","3":"13.30","4":"11.546","5":"9.296e-13"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>The intercept has the same coefficient (<span class="math inline">\(\hat\beta_0=-306.7\)</span>), SE, <span class="math inline">\(t\)</span>-value, and <span class="math inline">\(p\)</span>-value as the intercept from the models using base-2 and base-10 log-transformations of SAT. (This is, again, because <span class="math inline">\(2^0=10^0=e^0=1\)</span>.) And, although the coefficient and SE for the effect of SAT is again different (a one-unit change in the three different log-scales does not correspond to the same amount of change in raw SAT for the three models), the <span class="math inline">\(t\)</span>-value and level of statistical significance (<span class="math inline">\(t(31)=11.55\)</span>, <span class="math inline">\(p&lt;.001\)</span>) for this effect, are the same as when we used base-2 and base-10.</p>
<p>So how can we interpret the model’s coefficients?</p>
<ul>
<li>The intercept can be interpreted exactly the same as in the previous models in which we used base-2 or base-10; namely that the predicted average graduation rate for colleges/universities with a SAT value of one is <span class="math inline">\(-306.7\)</span>.</li>
<li>Interpreting the slope, we could say that an <span class="math inline">\(e\)</span>-fold difference in SAT value is associated with a 153.6-unit difference in graduation rates, on average.</li>
</ul>
<div id="interpretation-using-percentage-change" class="section level4">
<h4><span class="header-section-number">2.7.1.1</span> Interpretation Using Percentage Change</h4>
<p>Consider three schools, each having a SAT score that differs by 1%; say these schools have SAT values of 10, 10.1, 10.2. Using the fitted equation, we can compute the predicted graduation rate for each of these hypothetical schools:</p>
<p><span class="math display">\[
\hat{\mathrm{Graduation~Rate}} = -306.7 + 153.6 \bigg[\ln (\mathrm{SAT})\bigg]
\]</span></p>
<p>The SAT values and predicted graduation rates for these schools are given below:</p>
<table>
<caption>
<span id="tab:unnamed-chunk-51">Table 2.1: </span>SAT values and Graduation Rates for Three Hypothetical Schools that have SAT Values that Differ by One Percent.
</caption>
<thead>
<tr>
<th style="text-align:right;">
SAT
</th>
<th style="text-align:right;">
Predicted Graduation Rate
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
10.0
</td>
<td style="text-align:right;">
46.88
</td>
</tr>
<tr>
<td style="text-align:right;">
10.1
</td>
<td style="text-align:right;">
48.41
</td>
</tr>
<tr>
<td style="text-align:right;">
10.2
</td>
<td style="text-align:right;">
49.93
</td>
</tr>
</tbody>
</table>
<p>The difference between each subsequent predicted graduation rate is 1.53.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="fl">48.4058</span> <span class="op">-</span><span class="st"> </span><span class="fl">46.8778</span></code></pre>
<pre><code>[1] 1.528</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="fl">49.9338</span> <span class="op">-</span><span class="st"> </span><span class="fl">48.4058</span></code></pre>
<pre><code>[1] 1.528</code></pre>
<p>In other words, schools that have a SAT value that differ by 1%, have predicted graduation rates that differ by 1.53, on average.</p>
</div>
<div id="mathematical-explanation" class="section level4">
<h4><span class="header-section-number">2.7.1.2</span> Mathematical Explanation</h4>
<p>To understand how we can directly compute this difference, consider the predicted values for two <span class="math inline">\(x\)</span>-values that differ by one-percent, if we use symbolic notation:</p>
<p><span class="math display">\[
\begin{split}
\hat{y}_1 &amp;= \hat\beta_0 + \hat\beta_1\left[\ln(x)\right] \\
\hat{y}_2 &amp;= \hat\beta_0 + \hat\beta_1\left[\ln(1.01x)\right]
\end{split}
\]</span></p>
<p>The difference in their predicted values is:</p>
<p><span class="math display">\[
\begin{split}
\hat{y}_2 - \hat{y}_1 &amp;= \hat\beta_0 + \hat\beta_1\left[\ln(1.01x)\right] - \left(\hat\beta_0 + \hat\beta_1\left[\ln(x)\right]\right) \\
&amp;=\hat\beta_0 + \hat\beta_1\left[\ln(1.01x)\right] - \hat\beta_0 - \hat\beta_1\left[\ln(x)\right] \\
&amp;=\hat\beta_1\left[\ln(1.01x)\right] - \hat\beta_1\left[\ln(x)\right] \\
&amp;=\hat\beta_1\left[\ln(1.01x) - \ln(x)\right]\\
&amp;=\hat\beta_1\left[\ln(\frac{1.01x}{1x})\right]
\end{split}
\]</span></p>
<p>If we substitute in any value for <span class="math inline">\(x\)</span>, we can now directly compute this constant difference. Note that a convenient value for <span class="math inline">\(x\)</span> is 1. Then this reduces to:</p>
<p><span class="math display">\[
\hat\beta_1\left[\ln(1.01)\right]
\]</span></p>
<p>So now, we can interpret this as: a one-percent difference in <span class="math inline">\(x\)</span> is associated with a <span class="math inline">\(\hat\beta_1\left[\ln(1.01)\right]\)</span>-unit difference in <span class="math inline">\(Y\)</span>, on average.</p>
<p>In our model, we can compute this difference using the fitted coefficient <span class="math inline">\(\hat\beta_1=153.6\)</span> as</p>
<p><span class="math display">\[
153.6\left[\ln(1.01)\right] = 1.528371
\]</span></p>
<p>The same computation using R is</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="fl">153.6</span> <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(<span class="fl">1.01</span>)</code></pre>
<pre><code>[1] 1.528</code></pre>
<p>This gives you the constant difference exactly. So you can interpret the effect of SAT as, each 1% difference in SAT score is associated with a difference in graduation rates of 1.53, on average.</p>
</div>
<div id="approximate-interpretation" class="section level4">
<h4><span class="header-section-number">2.7.1.3</span> Approximate Interpretation</h4>
<p>We can get an approximate estimate for the size of the effect by using the mathematical shortcut of</p>
<p><span class="math display">\[
\mathrm{Effect} \approx \frac{\hat\beta_1}{100}
\]</span></p>
<p>Using our fitted results, we could approximate the size of the effect as,</p>
<p><span class="math display">\[
\frac{153.6}{100} = 1.536
\]</span></p>
<p>We could then interpret the effect of SAT by saying a 1% difference in median SAT score is associated with a 1.53-unit difference in predicted graduation rate, on average.</p>
</div>
</div>
</div>
<div id="including-covariates" class="section level2">
<h2><span class="header-section-number">2.8</span> Including Covariates</h2>
<p>We can also include covariates in the model. Below we examine the nonlinear effect of SAT on graduation controlling for differences in sector.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Fit model</span>
lm<span class="fl">.4</span> =<span class="st"> </span><span class="kw">lm</span>(grad <span class="op">~</span><span class="st"> </span><span class="dv">1</span> <span class="op">+</span><span class="st"> </span>public <span class="op">+</span><span class="st"> </span><span class="kw">log</span>(sat), <span class="dt">data =</span> mn)

<span class="co"># Model-level output</span>
<span class="kw">glance</span>(lm<span class="fl">.4</span>)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["r.squared"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["adj.r.squared"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["sigma"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["statistic"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["p.value"],"name":[5],"type":["dbl"],"align":["right"]},{"label":["df"],"name":[6],"type":["int"],"align":["right"]},{"label":["logLik"],"name":[7],"type":["dbl"],"align":["right"]},{"label":["AIC"],"name":[8],"type":["dbl"],"align":["right"]},{"label":["BIC"],"name":[9],"type":["dbl"],"align":["right"]},{"label":["deviance"],"name":[10],"type":["dbl"],"align":["right"]},{"label":["df.residual"],"name":[11],"type":["int"],"align":["right"]}],"data":[{"1":"0.8656","2":"0.8566","3":"6.338","4":"96.58","5":"8.466e-14","6":"3","7":"-106.2","8":"220.4","9":"226.4","10":"1205","11":"30"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>The model explains 86.5% of the variation in graduation rates, <span class="math inline">\(F(2,~30)=96.58\)</span>, <span class="math inline">\(p&lt;.001\)</span>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Coefficient-level output</span>
<span class="kw">tidy</span>(lm<span class="fl">.4</span>)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["term"],"name":[1],"type":["chr"],"align":["left"]},{"label":["estimate"],"name":[2],"type":["dbl"],"align":["right"]},{"label":["std.error"],"name":[3],"type":["dbl"],"align":["right"]},{"label":["statistic"],"name":[4],"type":["dbl"],"align":["right"]},{"label":["p.value"],"name":[5],"type":["dbl"],"align":["right"]}],"data":[{"1":"(Intercept)","2":"-286.069","3":"27.982","4":"-10.223","5":"2.729e-11"},{"1":"public","2":"-8.501","3":"2.444","4":"-3.479","5":"1.563e-03"},{"1":"log(sat)","2":"146.016","3":"11.616","4":"12.570","5":"1.736e-13"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<p>Interpreting each of the coefficients using the raw SAT scores:</p>
<ul>
<li>The intercept value of <span class="math inline">\(-286.1\)</span> is the predicted average graduation rate for all public colleges/universities with a SAT value of 1 (extrapolation).</li>
<li>There is a statistically significant effect of sector after controlling for differences in SAT score (<span class="math inline">\(p=.002\)</span>). Public schools have a predicted graduation rate that is 8.5-units lower, on average, than private schools controlling for differences in median SAT scores.</li>
<li>There is a statistically significant effect of SAT on graduation rates, controlling for differences in sector (<span class="math inline">\(p&lt;.001\)</span>). A 1% difference in median SAT value is associated with a 1.46-unit difference in predicted graduation rate, on average, after controlling for differences in sector.</li>
</ul>
<div id="plot-of-the-model-results" class="section level3">
<h3><span class="header-section-number">2.8.1</span> Plot of the Model Results</h3>
<p>To further help interpret these effects, we can plot the fitted model.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Set up data</span>
plot_data =<span class="st"> </span><span class="kw">crossing</span>(
  <span class="dt">sat =</span> <span class="kw">seq</span>(<span class="dt">from =</span> <span class="fl">8.9</span>, <span class="dt">to =</span> <span class="fl">14.0</span>, <span class="dt">by =</span> <span class="fl">.1</span>),
  <span class="dt">public =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>)
  ) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">mutate</span>(
    <span class="dt">yhat =</span> <span class="kw">predict</span>(lm<span class="fl">.4</span>, <span class="dt">newdata =</span> .),
    <span class="dt">public =</span> <span class="kw">factor</span>(public, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;Private&quot;</span>, <span class="st">&quot;Public&quot;</span>))
  )

<span class="co">#Examine data</span>
<span class="kw">head</span>(plot_data)</code></pre>
<div data-pagedtable="false">
<script data-pagedtable-source type="application/json">
{"columns":[{"label":["sat"],"name":[1],"type":["dbl"],"align":["right"]},{"label":["public"],"name":[2],"type":["fctr"],"align":["left"]},{"label":["yhat"],"name":[3],"type":["dbl"],"align":["right"]}],"data":[{"1":"8.9","2":"Private","3":"33.13"},{"1":"8.9","2":"Public","3":"24.63"},{"1":"9.0","2":"Private","3":"34.76"},{"1":"9.0","2":"Public","3":"26.26"},{"1":"9.1","2":"Private","3":"36.37"},{"1":"9.1","2":"Public","3":"27.87"}],"options":{"columns":{"min":{},"max":[10]},"rows":{"min":[10],"max":[10]},"pages":{}}}
  </script>
</div>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Plot</span>
<span class="kw">ggplot</span>(<span class="dt">data =</span> plot_data, <span class="kw">aes</span>(<span class="dt">x =</span> sat, <span class="dt">y =</span> yhat, <span class="dt">color =</span> public, <span class="dt">linetype =</span> public)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Median SAT score (in hundreds)&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;Predicted graduation rate&quot;</span>) <span class="op">+</span>
<span class="st">  </span>ggsci<span class="op">::</span><span class="kw">scale_color_d3</span>(<span class="dt">name =</span> <span class="st">&quot;Sector&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">scale_linetype_manual</span>(<span class="dt">name =</span> <span class="st">&quot;Sector&quot;</span>, <span class="dt">values =</span> <span class="kw">c</span>(<span class="st">&quot;solid&quot;</span>, <span class="st">&quot;dashed&quot;</span>))</code></pre>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-56"></span>
<img src="epsy-8252-notes_files/figure-html/unnamed-chunk-56-1.png" alt="Predicted graduation rate as a function of median SAT score (in hundreds) and sector. The effect of SAT is log-linear." width="50%" />
<p class="caption">
Figure 2.6: Predicted graduation rate as a function of median SAT score (in hundreds) and sector. The effect of SAT is log-linear.
</p>
</div>
<p>The plot shows the nonlinear, diminishing positive effect of SAT on graduation rate for both public and private schools. For schools with lower median SAT scores, there is a larger effect on graduation rates than for schools with higher median SAT scores (for both private and public schools). The plot also shows the controlled effect of sector. For schools with the same median SAT score, private schools have a higher predicted graduation rate than public schools, on average.</p>
</div>
</div>
<div id="polynomial-effects-vs.-log-transformations" class="section level2">
<h2><span class="header-section-number">2.9</span> Polynomial Effects vs. Log-Transformations</h2>
<p>The inclusion of polynomial effects and the use of a log-transformation was to model the nonlinearity observed in the relationship between SAT scores and graduation rates. Both methods were successful in this endeavor. While either method could be used in practice to model nonlinearity, there are some considerations when making the choice of which may be more appropriate for a given modeling situation.</p>
<p>The first consideration is one of theory. The plot below shows the mathematical function for a log-transformed <span class="math inline">\(X\)</span>-value (solid, black line) and for a quadratic polynomial of <span class="math inline">\(X\)</span> (dashed, red line).</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-57"></span>
<img src="epsy-8252-notes_files/figure-html/unnamed-chunk-57-1.png" alt="Comparison of quadratic (blue, dashed) and logarithmic (black, solid) functions of X." width="3in" />
<p class="caption">
Figure 2.7: Comparison of quadratic (blue, dashed) and logarithmic (black, solid) functions of X.
</p>
</div>
<p>Both functions are nonlinear, however the polynomial function changes direction. For low values of <span class="math inline">\(X\)</span>, the function has a large positive effect. This effect diminishes as <span class="math inline">\(X\)</span> gets bigger, and around <span class="math inline">\(X=9\)</span> the effect is zero. For larger values of <span class="math inline">\(X\)</span>, the effect is actually negative. For the logarithmic function, the effect is always positive, but it diminishes as <span class="math inline">\(X\)</span> gets larger. (Functions that constantly increase, or constantly decrease, are referred to as <em>monotonic functions</em>.) Theoretically, these are very different ideas, and if substantive literature suggests one or the other, you should probably acknowledge that in the underlying statistical model that is fitted.</p>
<p>Empirically, the two functions are very similar especially within certain ranges of <span class="math inline">\(X\)</span>. For example, although the predictions from these models would be quite different for really high values of <span class="math inline">\(X\)</span>, if we only had data from the range of 2 to 8 (<span class="math inline">\(2\leq X \leq 8\)</span>) both functions would produce similar residuals. In this case, the residuals would likely not suggest better fit for either of the two models. In this case, it might be prudent to think about Occam’s Razor—if two competing models produce similar predictions, adopt the simpler model. Between these two functions, the <strong>log-transformed model is simpler</strong>; it has one predictor compared to the two predictors in the quadratic model. The mathematical models make this clear:</p>
<p><span class="math display">\[
\begin{split}
\mathbf{Polynomial:~}Y_i &amp;= \beta_0 + \beta_1(X_i) + \beta_2(X_i^2) +\epsilon_i \\
\mathbf{Log\mbox{-}Transform:~}Y_i &amp;= \beta_0 + \beta_1\bigg[\ln(X_i)\bigg] + \epsilon_i
\end{split}
\]</span></p>
<p>The quadratic polynomial model has two effects: a linear effect of <span class="math inline">\(X\)</span> and a quadratic effect of <span class="math inline">\(X\)</span> (remember it is an interaction model), while the model using the log-transformed predictor only has a single effect. If there is no theory to guide your model’s functional form, and the residuals from the polynomial and log-transformed models seem to fit equally well, then the log-transformed model saves you a degree of freedom, and probably should be adopted.</p>
<p><br /></p>
<hr />
</div>
<div id="other-resources-1" class="section level2 unnumbered">
<h2>Other Resources</h2>
<p>In addition to the notes and what we cover in class, there are many other resources for learning about log-transformations. Here are some resources that may be helpful in that endeavor:</p>
<ul>
<li><a href="https://www.cscu.cornell.edu/news/statnews/stnews83.pdf">Interpreting Coefficients in Regression with Log-Transformed Variables</a></li>
<li><a href="http://www.cazaar.com/ta/econ113/interpreting-beta">Interpret Regression Coefficient Estimates</a></li>
</ul>
<p><br /></p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="pretty-printing-tables-in-markdown.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="nonlinearity-log-transforming-the-outcome.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": {},
"instapper": false
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
},
"collapse": "section",
"toolbar": null,
"position": "fixed",
"search": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
